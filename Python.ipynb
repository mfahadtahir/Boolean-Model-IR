{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 IR | Boolean Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Finding Words from Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Length:  6766\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    " \n",
    "ps = PorterStemmer()\n",
    "\n",
    "def readFile(file):\n",
    "    f = open(f'./ShortStories/{file}.txt',encoding=\"utf8\")\n",
    "    #   Read and Lower Case \n",
    "    line = f.read().lower()    \n",
    "        \n",
    "    #   Removing Punctuations\n",
    "    line = line.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "    # We have identified all unique characters and numbers and removed all others but alphabets       \n",
    "    # '9', '0', '—', 'i', 'u', 'q', '2', 'e', 'ª', 'z', 'y', '”', '8', 'd', 'v', 'o', 'm', 'f', 'b', '¨', '7', '1', 'a', '’', 'l', 'w', '§', 'j', '“', 'x', 'g', '©', 'p', '6', '3', 'r', 'c', 't', 'ã', '5', '´', '¯', '‘', 'h', '4', 's', 'k', 'n\n",
    "    line = line.translate(str.maketrans('','','1234567890©§“”‘’\"´¨¯—ªã'))\n",
    "        \n",
    "    for word in line.split():\n",
    "        dictionary.add(ps.stem(word))\n",
    "\n",
    "    f.close()\n",
    "    return\n",
    "dictionary = set()\n",
    "\n",
    "# Run for Each File\n",
    "for x in range(1,51):\n",
    "    readFile(x)\n",
    "    \n",
    "dictionary.difference_update(stopwords)\n",
    "\n",
    "print(\"Dictionary Length: \", len(dictionary))\n",
    "# print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Removing StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Length:  6763\n"
     ]
    }
   ],
   "source": [
    "f = open(\"stopwords.txt\", \"r\")\n",
    "# while(1):\n",
    "stopWords = f.read().split()\n",
    "for stopword in stopWords:\n",
    "    dictionary.discard(ps.stem(stopword))\n",
    "f.close()\n",
    "print(\"Dictionary Length: \", len(dictionary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Writing Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"dictionary.txt\", \"w\")\n",
    "\n",
    "with open('dictionary.txt', 'w') as the_file:\n",
    "    for word in dictionary:\n",
    "        f.write(f'{word}\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding All Characters used before translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9', '0', '—', 'i', 'u', 'q', '2', 'e', 'ª', 'z', 'y', '”', '8', 'd', 'v', 'o', 'm', 'f', 'b', '¨', '7', '1', 'a', '’', 'l', 'w', '§', 'j', '“', 'x', 'g', '©', 'p', '6', '3', 'r', 'c', 't', 'ã', '5', '´', '¯', '‘', 'h', '4', 's', 'k', 'n'}\n"
     ]
    }
   ],
   "source": [
    "allchars = set()    \n",
    "for word in dictionary:\n",
    "        for letter in word:\n",
    "            allchars.add(letter)\n",
    "print(allchars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line:  my long strings big  sentance antisocial different string\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import string \n",
    "\n",
    "\n",
    "    #   Read a Line and work on it and repeat\n",
    "line = \"my long string's big 9 sentance anti-social different 1str@ing!\"\n",
    "        \n",
    "    #   End of line Found\n",
    "\n",
    "line = line.lower()\n",
    "line = line.translate(str.maketrans('','',string.punctuation))\n",
    "line = line.translate(str.maketrans('','','1234567890'))\n",
    "line = line.translate(str.maketrans('','','“”‘’\"—'))\n",
    "\n",
    "# words = word_tokenize(line)\n",
    "\n",
    "print(\"Line: \", line)\n",
    "# print(\"Words: \", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my  \t\t:\t my\n",
      "long  \t\t:\t long\n",
      "string  \t\t:\t string\n",
      "'s  \t\t:\t 's\n",
      "big  \t\t:\t big\n",
      "sentance  \t\t:\t sentanc\n",
      "that-make  \t\t:\t that-mak\n",
      "different  \t\t:\t differ\n",
      "1str  \t\t:\t 1str\n",
      "@  \t\t:\t @\n",
      "ing  \t\t:\t ing\n",
      "!  \t\t:\t !\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download()\n",
    "# importing modules\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(\"my long string's big sentance that-make different 1str@ing!\")\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for w in words:\n",
    "    print(w, \" \\t\\t:\\t\", ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a a\n",
      "is is\n",
      "the the\n",
      "of of\n",
      "all all\n",
      "and and\n",
      "to to\n",
      "can can\n",
      "be be\n",
      "as as\n",
      "once onc\n",
      "for for\n",
      "at at\n",
      "am am\n",
      "are are\n",
      "has ha\n",
      "have have\n",
      "had had\n",
      "up up\n",
      "his hi\n",
      "her her\n",
      "in in\n",
      "on on\n",
      "no no\n",
      "we we\n",
      "do do\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "f = open(\"stopwords.txt\", \"r\")\n",
    "stopwords = []\n",
    "while(1):\n",
    "    line = f.readline().strip()\n",
    "    if(not line):\n",
    "        break\n",
    "    stopwords.append(line)\n",
    "f.close()\n",
    "for psword in stopwords:\n",
    "    print(psword, ps.stem(psword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
